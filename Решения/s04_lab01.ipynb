{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c56ca2a2",
   "metadata": {},
   "source": [
    "# Лабораторная 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb66331",
   "metadata": {},
   "source": [
    "***План лабораторной;***\n",
    "\n",
    "1. Постановка задачи обучения с учителем. Признаки объекта. Типы задач.\n",
    "2. Классический k-NN. Взвешенный k-NN. k-NN в sсikit-learn. Ядра и метод потенциальных функций\n",
    "3. Итоги"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1954d971",
   "metadata": {},
   "source": [
    "## 1.1 Постановка задачи обучения с учителем"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4689b884",
   "metadata": {},
   "source": [
    "Пусть \n",
    "\n",
    "* $X$ - множество объектов, или же, что более точно множество их информационных описаний\n",
    "* $Y$ - множество ответов \n",
    "* $y: X \\rightarrow Y$ - некоторая неизвестная зависимость\n",
    "\n",
    "Задача ***обучения с учителем выглядит следующим образом*** \n",
    "\n",
    "***Дано:*** \n",
    "\n",
    "$ {x_1 ... x_l} \\subset X $ - обучающая выборка \n",
    "\n",
    "$y_1 = y(x_1) ... y_l = y(x_l)$ - ответы\n",
    "\n",
    "***Требуется найти:*** \n",
    "\n",
    "$a: X \\rightarrow Y $ - алгоритм, приближающий $y$ на множестве $X$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b242705",
   "metadata": {},
   "source": [
    "## 1.2 Признаки объекта"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d480c9c8",
   "metadata": {},
   "source": [
    "Для того чтобы работать с объектами, алгоритм должен опираться на какие-то свойства объекта. Эти свойства и есть *признаки* объекта, а их множество является *признаковым описанием* объекта. \n",
    "\n",
    "Более срого ***признаки*** объекта $ f_j $ задаются следующим образом: \n",
    "\n",
    "$f_j : X \\rightarrow D_j$ \n",
    "\n",
    "*Типы признаков*:\n",
    "\n",
    "1. Бинарные (пример: наличие или отсутствие ванной комнаты у квартиры, наличие или отсутствие детей у пассажира титаника) \n",
    "2. Численные (пример: рост и вес человека, мощность двигателя машины) \n",
    "3. Категориальные (пример: день недели, погода) \n",
    "\n",
    "***Важно и очень важно*** понимать разницу между объектом и его признаковым описанием."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109b379d",
   "metadata": {},
   "source": [
    "## 1.3 Типы задач"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bcda223",
   "metadata": {},
   "source": [
    "1. ***Задача бинарной классификации*** - $Y = \\{0, 1\\}$\n",
    "\n",
    "Пример: вернёт ли клиент кредит, болен ли пациент. \n",
    "\n",
    "2. ***Задача классификации на M непересекающихся классов*** - $Y = \\{0 ... M\\}$\n",
    "\n",
    "Пример: классификация рукописных цифр. \n",
    "\n",
    "3. ***Задача классификации на M пересекающихся классов*** - $Y = \\{0, 1\\}^M$\n",
    "\n",
    "Пример: жанр для фильма(фильм может иметь несколько жанров). \n",
    "\n",
    "4. ***Задача регрессии*** - $Y = R$\n",
    "\n",
    "Пример: время выполнения программы. \n",
    "\n",
    "5. ***Задача ранжирования*** - $Y$ - упорядоченное множество.\n",
    "\n",
    "Пример: Поисковый запрос. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41854263",
   "metadata": {},
   "source": [
    "### Задача 1(1 балл)\n",
    "\n",
    "Загрузим датасет Ирисы Фишера. \n",
    "\n",
    "***Датасет ирисов Фишера*** впервые представлен британским статистиком и биологом Рональдом Фишером в 1936 году. Датасет состоит из измерений четырех признаков (длина наружной доли околоцветника, ширина наружной доли околоцветника, длина внутренней доли околоцветника, ширина внутренней доли околоцветника) и трех видов ирисов: setosa, versicolor и virginica.\n",
    "\n",
    "Датасет содержит 150 экземпляров ирисов, по 50 для каждого вида. Ирисы Фишера часто используется для демонстрации методов классификации и кластеризации в машинном обучении, а также для иллюстрации визуализации данных и кластерного анализа.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7cbc0a",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mДля выполнения ячеек с \"base\" требуется пакет ipykernel.\n",
      "\u001b[1;31mВыполните следующую команду, чтобы установить \"ipykernel\" в среде Python. \n",
      "\u001b[1;31mКоманда: \"conda install -n base ipykernel --update-deps --force-reinstall\""
     ]
    }
   ],
   "source": [
    "# библиотеки, используемые в лабораторной работе\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.datasets import make_circles\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b3ba71",
   "metadata": {},
   "source": [
    "Визуализируем датасет "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe717f3a",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mДля выполнения ячеек с \"base\" требуется пакет ipykernel.\n",
      "\u001b[1;31mВыполните следующую команду, чтобы установить \"ipykernel\" в среде Python. \n",
      "\u001b[1;31mКоманда: \"conda install -n base ipykernel --update-deps --force-reinstall\""
     ]
    }
   ],
   "source": [
    "iris_dataset = sns.load_dataset('iris')\n",
    "sns.pairplot(iris_dataset, hue='species')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6778615",
   "metadata": {},
   "source": [
    "1. Сколько объектов в данном датасете?\n",
    "2. Сколько признаков у каждого объекта?\n",
    "3. Какие типы признаков у каждого объекта?\n",
    "4. Какой тип задачи можно решить с помощью данного даного датасета?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b869b77",
   "metadata": {},
   "source": [
    "1. В датасете Ирисы Фишера содержится 150 объектов.\n",
    "\n",
    "2. У каждого объекта четыре признака, которые являются измерениями частей цветка: длина наружной дольки околоцветника (англ. sepal length), ширина наружной дольки околоцветника (англ. sepal width), длина внутренней дольки околоцветника (англ. petal length), и ширина внутренней дольки околоцветника (англ. petal width). Также в датасете присутствует метка класса, указывающая на вид ириса, к которому относится объект.\n",
    "\n",
    "3. Все четыре признака у каждого объекта — это количественные (вещественные числа), измеряемые в сантиметрах.\n",
    "\n",
    "4. Используя данный датасет, можно решать задачи классификации, при которых предсказывается вид ириса на основе измерений его частей цветка. Также его можно использовать для задачи кластеризации (например, для проверки алгоритмов, которые могли бы группировать наблюдения в три различные группы в соответствии с видами ирисов без предварительного знания их меток). Кроме того, данный датасет подходит для визуализации данных и обучения в области машинного обучения, так как он не очень большой и имеет четкую структуру."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc394dd",
   "metadata": {},
   "source": [
    "## 2.1 Метрические методы классификации"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c147a68a",
   "metadata": {},
   "source": [
    "***Гипотеза компактности***\n",
    "\n",
    "Гипотеза компактности - это основная идея, лежащая в основе алгоритмов k-ближайших соседей (k-NN) в машинном обучении. Она предполагает, что объекты одного класса скорее всего находятся близко друг к другу в пространстве признаков. Другими словами, объекты, принадлежащие к одному классу, склонны иметь похожие значения признаков и, следовательно, будут расположены близко друг к другу в пространстве признаков.\n",
    "\n",
    "***Гипотеза непрерывности***\n",
    "\n",
    "Гипотеза непрерывности подразумевает, что объекты, находящиеся близко друг к другу в пространстве признаков, имеют близкие значения целевой переменной или принадлежат к одному и тому же классу. Это предположение позволяет алгоритмам классификации учитывать близость объектов при принятии решений о принадлежности к классу."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e95bc7",
   "metadata": {},
   "source": [
    "Посмотрите на выборку выше и убедитесь в выполнимости гипотезы непрерывности и компактности. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2fcf41",
   "metadata": {},
   "source": [
    "***Алгоритм k-ближайших соседей (k-NN)*** является одним из простейших методов для классификации объектов в машинном обучении. Он основан на принципе гипотезы компактности и непрерывности: объекты одного класса склонны находиться близко друг к другу в пространстве признаков.\n",
    "\n",
    "Фраза, которая хорошая объясняет работу алгоритма: ***\"Скажи мне, кто твой друг, и я скажу, кто ты\"***. Также стоит отметить, что метрические алгоритмы почти не имеют фазы обучения. Алгоритм просто запоминают всю обучающую выборку, а на этапе предсказания просто ищут похожие на целевой объекты. \n",
    "\n",
    "Такое обучение называется ***lazy learning***.  \n",
    "\n",
    "***Принцип работы алгоритма k-NN***:\n",
    "\n",
    "1. Загрузка обучающего набора данных, содержащего объекты и соответствующие им классы.\n",
    "2. Для нового объекта вычисляется расстояние до всех объектов обучающего набора с использованием метрики расстояния, например, евклидово расстояние.\n",
    "3. Выбираются k ближайших соседей нового объекта из обучающего набора данных.\n",
    "4. Определяется класс нового объекта на основе классов его ближайших соседей (например, путем простого большинства среди соседей).\n",
    "5. Новый объект относится к тому классу, который представлен большинством среди его k ближайших соседей.\n",
    "\n",
    "Параметр k является гиперпараметром алгоритма, и его выбор влияет на точность классификации. Большие значения k могут быть более устойчивыми к выбросам, но более склонны к обобщению, в то время как малые значения k склонны к чувствительности к шумам, но могут иметь плохую предсказательную способность. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfbc6c8e",
   "metadata": {},
   "source": [
    "Работа алгоритма хорошо продемонстрирована на схеме ниже:\n",
    "1. У нас есть обучающая выборка из \"синих квадратов\" и \"красных треугольников\". Нам нужно понять к какому классу относится зелёный круг.\n",
    "2. Для зелёного круга вычисляем расстояние до всех объектов обучающего набора. \n",
    "3. Выбираем k ближайших соседей зелёного круга(в нашем случае k = 3).\n",
    "4. Определяется класс зелёного круга на основе классов его ближайших соседей (например, путем простого большинства среди соседей).\n",
    "5. Зелёный круг относится к тому классу, который представлен большинством среди его k ближайших соседей(в нашем случае круг окажется треугольником). "
   ]
  },
  {
   "attachments": {
    "KnnClassification.svg.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "b6e2980d",
   "metadata": {},
   "source": [
    "![KnnClassification.svg.png](attachment:KnnClassification.svg.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24bc04c8",
   "metadata": {},
   "source": [
    "***Реализуем алгоритм k-nn своими руками***:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4671bc",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mДля выполнения ячеек с \"base\" требуется пакет ipykernel.\n",
      "\u001b[1;31mВыполните следующую команду, чтобы установить \"ipykernel\" в среде Python. \n",
      "\u001b[1;31mКоманда: \"conda install -n base ipykernel --update-deps --force-reinstall\""
     ]
    }
   ],
   "source": [
    "np.bincount([1, 1, 2, 3, 0, 0, 0, 7, 7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f2d67f",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mДля выполнения ячеек с \"base\" требуется пакет ipykernel.\n",
      "\u001b[1;31mВыполните следующую команду, чтобы установить \"ipykernel\" в среде Python. \n",
      "\u001b[1;31mКоманда: \"conda install -n base ipykernel --update-deps --force-reinstall\""
     ]
    }
   ],
   "source": [
    "# Функция для вычисления евклидова расстояния между точками\n",
    "def euclidean_distance(x1, x2):\n",
    "    return np.sqrt(np.sum((x1 - x2)**2))\n",
    "\n",
    "# Класс, представляющий алгоритм k-NN\n",
    "class KNN:\n",
    "    def __init__(self, k=3):\n",
    "        self.k = k\n",
    "\n",
    "    # Метод для обучения модели\n",
    "    def fit(self, X, y):\n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "\n",
    "    # Метод для предсказания класса нового объекта\n",
    "    def predict(self, X):\n",
    "        y_pred = [self._predict(x) for x in X]\n",
    "        return np.array(y_pred)\n",
    "\n",
    "    # Внутренний метод для предсказания класса для одного объекта\n",
    "    def _predict(self, x):\n",
    "        # Вычисляем расстояние до всех объектов в обучающем наборе\n",
    "        distances = [euclidean_distance(x, x_train) for x_train in self.X_train]\n",
    "        # Сортируем по расстоянию и возвращаем индексы k ближайших соседей\n",
    "        k_indices = np.argsort(distances)[:self.k]\n",
    "        # Получаем метки классов ближайших соседей\n",
    "        k_nearest_labels = [self.y_train[i] for i in k_indices]\n",
    "        # Возвращаем наиболее часто встречающийся класс\n",
    "        most_common = np.bincount(k_nearest_labels).argmax()\n",
    "        return most_common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24779a3",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mДля выполнения ячеек с \"base\" требуется пакет ipykernel.\n",
      "\u001b[1;31mВыполните следующую команду, чтобы установить \"ipykernel\" в среде Python. \n",
      "\u001b[1;31mКоманда: \"conda install -n base ipykernel --update-deps --force-reinstall\""
     ]
    }
   ],
   "source": [
    "# Загрузим датасет ирисов\n",
    "iris = datasets.load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# Разделим на обучающую и тестовую выборку\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=22)\n",
    "\n",
    "# Создадим и обучим модель k-NN\n",
    "clf = KNN(k=3)\n",
    "clf.fit(X_train, y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "\n",
    "# Оценим точность модели\n",
    "accuracy = np.mean(predictions == y_test)\n",
    "print(f\"Точность: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f47abf",
   "metadata": {},
   "source": [
    "### Задача2(1 балл)\n",
    "\n",
    "1. Используя модель, приведённую выше, реализуйте k-nn с ***метрикой манхэттен***.\n",
    "2. Постройте график зависимости точности алгоритма от числа соседей(k = 1, 2 ... 10)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0168f29",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mДля выполнения ячеек с \"base\" требуется пакет ipykernel.\n",
      "\u001b[1;31mВыполните следующую команду, чтобы установить \"ipykernel\" в среде Python. \n",
      "\u001b[1;31mКоманда: \"conda install -n base ipykernel --update-deps --force-reinstall\""
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Функция для вычисления Манхэттенского расстояния между точками\n",
    "def manhattan_distance(x1, x2):\n",
    "    return np.sum(np.abs(x1 - x2))\n",
    "\n",
    "# Класс, представляющий алгоритм k-NN с метрикой Манхэттен\n",
    "class KNN:\n",
    "    def __init__(self, k=3, distance_func=manhattan_distance):\n",
    "        self.k = k\n",
    "        self.distance_func = distance_func\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "\n",
    "    def predict(self, X):\n",
    "        y_pred = [self._predict(x) for x in X]\n",
    "        return np.array(y_pred)\n",
    "\n",
    "    def _predict(self, x):\n",
    "        distances = [self.distance_func(x, x_train) for x_train in self.X_train]\n",
    "        k_indices = np.argsort(distances)[:self.k]\n",
    "        k_nearest_labels = [self.y_train[i] for i in k_indices]\n",
    "        most_common = np.bincount(k_nearest_labels).argmax()\n",
    "        return most_common\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100e4805",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mДля выполнения ячеек с \"base\" требуется пакет ipykernel.\n",
      "\u001b[1;31mВыполните следующую команду, чтобы установить \"ipykernel\" в среде Python. \n",
      "\u001b[1;31mКоманда: \"conda install -n base ipykernel --update-deps --force-reinstall\""
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Функция для вычисления Манхэттенского расстояния между точками\n",
    "def manhattan_distance(x1, x2):\n",
    "    return np.sum(np.abs(x1 - x2))\n",
    "\n",
    "# Весь код здесь для класса KNN...\n",
    "\n",
    "# Загрузим датасет ирисов\n",
    "iris = datasets.load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# Разделим на обучающую и тестовую выборку\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=22)\n",
    "\n",
    "accuracies = []\n",
    "\n",
    "# Проверим точность для разных значений k\n",
    "for k in range(1, 11):\n",
    "    # Создаем и обучаем модель k-NN с метрикой Манхэттен\n",
    "    clf = KNN(k=k, distance_func=manhattan_distance)\n",
    "    clf.fit(X_train, y_train)\n",
    "    predictions = clf.predict(X_test)\n",
    "    \n",
    "    # Оценим точность модели\n",
    "    accuracy = np.mean(predictions == y_test)\n",
    "    accuracies.append(accuracy)\n",
    "    \n",
    "# Строим график зависимости точности от k\n",
    "plt.plot(range(1, 11), accuracies, marker='o')\n",
    "plt.title('Accuracy vs. Number of Neighbors (k)')\n",
    "plt.xlabel('Number of Neighbors (k)')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xticks(range(1, 11))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75215a8",
   "metadata": {},
   "source": [
    "## 2.2 Взвешенный k-nn "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b620a07b",
   "metadata": {},
   "source": [
    "У нашего алгоритма есть недостаток: он ***никак не учитывает*** расстояния до соседних объектов. Однако данная информация зачастую может быть важна. Этот недостаток устраняет взвешенный k-NN.\n",
    "\n",
    "Принцип работы ***взвешенного алгоритма k-NN*** следующий:\n",
    "\n",
    "1. Вычисление расстояния: для каждого объекта тестовой выборки вычисляются расстояния до всех объектов обучающей выборки (обычно используется евклидово расстояние, но могут быть использованы и другие метрики, такие как манхэттенское расстояние, косинусное расстояние и т. д.).\n",
    "\n",
    "2. Нахождение k ближайших соседей: выбираются k обучающих объектов с наименьшими расстояниями до данного тестового объекта.\n",
    "\n",
    "3. ***Присвоение весов***: каждому из ближайших соседей присваивается вес, который обратно пропорционален расстоянию до него. Чем меньше расстояние, тем больший вес получает сосед. Обычно используется функция, которая дает больший вес ближайшим соседям и меньший вес более отдаленным.\n",
    "\n",
    "4. Прогнозирование класса: после вычисления весов каждого из соседей, для прогнозирования класса тестового объекта используется взвешенное голосование с учетом весов. То есть, каждый сосед голосует за свой класс, причем его голос взвешивается соответственно весу этого соседа. Итоговый класс определяется классом, получившим наибольшую сумму взвешенных голосов.\n",
    "\n",
    "Рассмотрим пункт 3-4 более подробно. \n",
    "\n",
    "Пусть у нас имеется k ближайщих соседей. Самый близкий будет иметь номер 1, самый дальний номер k. Введём для каждого соседа вес - $w_i$, который зависит от номера соседа. \n",
    "\n",
    "При этом, наиболее распространённый выбор $w_i$:\n",
    "\n",
    "* $w_i = \\frac{k - i + 1}{k}$ - линейные веса \n",
    "\n",
    "* $w_i = q^i$, $0 < q < 1$ - экспоненциальные веса \n",
    "\n",
    "Тогда класс объекта $u$ будет вычисляться по формуле: $a(u) = argmax( \\sum_{i = 1}^k w_i I(y_i = y))$\n",
    "\n",
    "где $y_i$ - класс объекта $x_i$, а $I$ - функция принимающая значение 1 в случае верности тождества в скобках и 0 в других случаях.  \n",
    "\n",
    "Таким образом нам нужно найти такое значение $y$ при котором выражение $a(u)$ будет максимальным. То есть теперь мы выбираем класс объекта не путем простого большинства среди соседей, а путем большинства среди соседей с ***некоторыми весами***. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f29779f",
   "metadata": {},
   "source": [
    "### Задача 3(2 балла)\n",
    "\n",
    "1. Реализуйте взвешенный k-nn.  \n",
    "2. Рассчитайте точность работы алгоритма. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c106a13",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mДля выполнения ячеек с \"base\" требуется пакет ipykernel.\n",
      "\u001b[1;31mВыполните следующую команду, чтобы установить \"ipykernel\" в среде Python. \n",
      "\u001b[1;31mКоманда: \"conda install -n base ipykernel --update-deps --force-reinstall\""
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Загружаем датасет\n",
    "iris = datasets.load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# Разделим на обучающую и тестовую выборку\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=22)\n",
    "\n",
    "class KNN_Weighted:\n",
    "    def __init__(self, k=3):\n",
    "        self.k = k\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "\n",
    "    def predict(self, X):\n",
    "        y_pred = [self._predict(x) for x in X]\n",
    "        return np.array(y_pred)\n",
    "\n",
    "    def _predict(self, x):\n",
    "        # Вычисляем расстояния от x до всех точек в обучающем наборе\n",
    "        distances = [euclidean_distance(x, x_train) for x_train in self.X_train]\n",
    "\n",
    "        # Получаем индексы отсортированных элементов (от меньшего к большему)\n",
    "        k_indices = np.argsort(distances)[:self.k]\n",
    "\n",
    "        # Получаем k ближайших меток\n",
    "        k_nearest_labels = [self.y_train[i] for i in k_indices]\n",
    "\n",
    "        # Вычисляем веса для k ближайших соседей (обратно пропорциональные расстояниям)\n",
    "        weights = [1 / distances[i] if distances[i] != 0 else float('inf') for i in k_indices]\n",
    "\n",
    "        # Считаем взвешенную сумму меток для прогнозируемого значения\n",
    "        label_weights = np.bincount(k_nearest_labels, weights=weights)\n",
    "\n",
    "        # Возвращаем метку с наибольшим весом\n",
    "        return np.argmax(label_weights)\n",
    "\n",
    "# Обучение модели\n",
    "k = 3 # Вы можете экспериментировать с разным числом k\n",
    "clf_weighted = KNN_Weighted(k=k)\n",
    "clf_weighted.fit(X_train, y_train)\n",
    "\n",
    "# Предсказание меток для тестового набора данных\n",
    "predictions_weighted = clf_weighted.predict(X_test)\n",
    "\n",
    "# Точность модели\n",
    "accuracy_weighted = np.mean(predictions_weighted == y_test)\n",
    "print(f'Точность взвешенного KNN: {accuracy_weighted}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1b2e5f",
   "metadata": {},
   "source": [
    "## 2.3 k-NN в sсikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8e6101",
   "metadata": {},
   "source": [
    "Конечно же k-NN реализован в sсikit-learn и представлен классом `KNeighborsClassifier` в модуле `neighbors`. Вот основные гиперпараметры этого классификатора:\n",
    "\n",
    "1. `n_neighbors`: Число соседей, которые используются для классификации каждого образца. Это, вероятно, самый важный гиперпараметр в классификаторе k-NN.\n",
    "\n",
    "2. `weights`: Этот параметр позволяет задать веса, используемые для голосования среди соседей. Возможные значения:\n",
    "- `uniform`: все соседи вносят одинаковый вклад в голосование.\n",
    "- `distance`: вес каждого соседа зависит от расстояния, то есть ближайшие соседи имеют больший вес.\n",
    "\n",
    "3. `p`: Параметр метрики расстояния. По умолчанию, p=2, что соответствует евклидовой метрике. Однако можно установить p=1, чтобы использовать манхэттенскую метрику.\n",
    "\n",
    "4. `metric`: Метрика расстояния. По умолчанию используется метрика Минковского, которая имеет параметр p. Однако можно также указать другие метрики, такие как косинусное расстояние, Жаккарда и другие."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac9c007",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mДля выполнения ячеек с \"base\" требуется пакет ipykernel.\n",
      "\u001b[1;31mВыполните следующую команду, чтобы установить \"ipykernel\" в среде Python. \n",
      "\u001b[1;31mКоманда: \"conda install -n base ipykernel --update-deps --force-reinstall\""
     ]
    }
   ],
   "source": [
    "# Загружаем датасет ирисах Фишера\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Разделяем на обучающую и тестовую выборку\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=22)\n",
    "\n",
    "# Создаем объект классификатора k-ближайших соседей\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# Обучаем модель на обучающих данных\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Делаем предсказания на тестовых данных\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# Оцениваем точность модели\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Точность модели k-ближайших соседей на датасете:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3dd00e7",
   "metadata": {},
   "source": [
    "### Задача 4(2 балла)\n",
    "\n",
    "1. Загрузите датасет 'breast_cancer' и отнормируйте данные.\n",
    "2. Постройте графики зависимости точности алгоритма от числа ближайщих соседей(k = 1,2...10).\n",
    "3. Найдите какое значение параметра weights даёт лучший результат при k = 5.\n",
    "4. Найдите какое значение параметра metric даёт лучший результат при k = 5.\n",
    "5. Найдите тройку k, weights, metric дающую лучшую точность. \n",
    "\n",
    "***Используйте разбиение X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=22)!***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "905ba908",
   "metadata": {},
   "source": [
    "Набор данных о раке груди, доступный в библиотеке scikit-learn, содержит информацию о различных признаках изображений, полученных с помощью цифровой маммографии. Эти признаки были извлечены из изображений и могут быть использованы для диагностики рака груди. Вот некоторые из ключевых признаков в этом наборе данных:\n",
    "\n",
    "1. Радиус (среднее расстояние от центра до периферии)\n",
    "2. Текстура (стандартное отклонение значений шкал серого цвета)\n",
    "3. Площадь\n",
    "4. Гладкость (локальные вариации по длине радиуса)\n",
    "5. Периметр\n",
    "6. Площадь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3497bde",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mДля выполнения ячеек с \"base\" требуется пакет ipykernel.\n",
      "\u001b[1;31mВыполните следующую команду, чтобы установить \"ipykernel\" в среде Python. \n",
      "\u001b[1;31mКоманда: \"conda install -n base ipykernel --update-deps --force-reinstall\""
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Загружаем датасет о раке груди\n",
    "cancer = load_breast_cancer()\n",
    "X = cancer.data\n",
    "y = cancer.target\n",
    "\n",
    "# Нормирование данных\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Разбиение на тренировочные и тестовые данные\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=22)\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Список для хранения точности\n",
    "accuracies = []\n",
    "\n",
    "# Итерация по числу соседей от 1 до 10\n",
    "for k in range(1, 11):\n",
    "    classifier = KNeighborsClassifier(n_neighbors=k)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "# Построение графика\n",
    "plt.plot(range(1, 11), accuracies, marker='o')\n",
    "plt.xlabel('Число ближайших соседей (k)')\n",
    "plt.ylabel('Точность')\n",
    "plt.title('Зависимость точности от k')\n",
    "plt.xticks(range(1, 11))\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "# Список для хранения точности для разных значений параметра weights\n",
    "weights_options = ['uniform', 'distance']\n",
    "best_weight_acc = 0\n",
    "best_weight = ''\n",
    "\n",
    "# Итерация по значениям параметра weights\n",
    "for weight in weights_options:\n",
    "    classifier = KNeighborsClassifier(n_neighbors=5, weights=weight)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    if accuracy > best_weight_acc:\n",
    "        best_weight_acc = accuracy\n",
    "        best_weight = weight\n",
    "\n",
    "print(f'Лучшее значение weights: {best_weight} с точностью: {best_weight_acc}')\n",
    "# Список для хранения точности для разных значений параметра metric\n",
    "metrics_options = ['euclidean', 'manhattan', 'chebyshev', 'minkowski']\n",
    "best_metric_acc = 0\n",
    "best_metric = ''\n",
    "\n",
    "# Итерация по значениям параметра metric\n",
    "for metric in metrics_options:\n",
    "    classifier = KNeighborsClassifier(n_neighbors=5, metric=metric)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    if accuracy > best_metric_acc:\n",
    "        best_metric_acc = accuracy\n",
    "        best_metric = metric\n",
    "\n",
    "print(f'Лучшее значение metric: {best_metric} с точностью: {best_metric_acc}')\n",
    "# Поиск лучшей тройки (k, weights, metric)\n",
    "best_overall_acc = 0\n",
    "best_overall_k = 0\n",
    "best_overall_weight = ''\n",
    "best_overall_metric = ''\n",
    "\n",
    "for k in range(1, 11):\n",
    "    for weight in weights_options:\n",
    "        for metric in metrics_options:\n",
    "            classifier = KNeighborsClassifier(n_neighbors=k, weights=weight, metric=metric)\n",
    "            classifier.fit(X_train, y_train)\n",
    "            y_pred = classifier.predict(X_test)\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            if accuracy > best_overall_acc:\n",
    "                best_overall_acc = accuracy\n",
    "                best_overall_k = k\n",
    "                best_overall_weight = weight\n",
    "                best_overall_metric = metric\n",
    "\n",
    "print(f'Лучшее значение тройки (k, weights, metric): {best_overall_k}, {best_overall_weight}, {best_overall_metric} с точностью: {best_overall_acc}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22cea264",
   "metadata": {},
   "source": [
    "### 2.4 Ядра и метод потенциальных функций"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02315cc",
   "metadata": {},
   "source": [
    "До сих пор мы использовали веса, зависящие от номера соседа, но напрямую не зависящие от расстояния до него.\n",
    "\n",
    "Пусть есть объект $x$, который мы хотим классифицировать. Введём $w_i(x) = K(\\frac{r(x_i,x)}{h})$, где r$(x_i,x)$ - расстояние между между $x$ и его i-соседом.  \n",
    "\n",
    "$K(r)$ - ядро, не возрастает и положительно на $[0;1]$, h - ширина окна. \n",
    "\n",
    "На практике в качестве $К(r)$ используют:\n",
    "\n",
    "* $K(r) = \\frac{1}{2}I(|x| <= 1)$ - ***прямоугольное ядро***\n",
    "* $K(r) = \\frac{1}{\\sqrt(2\\pi))}e^{-2x^2}$ - ***гауссово ядро***\n",
    "\n",
    "***Метод потенциальных функций***\n",
    "\n",
    "Возьмём в качестве веса $w_i = q^i K(\\frac{r(x_i, x)}{h_i})$. Здесь есть ***прямая аналогия с физикой***.\n",
    "\n",
    "* $q^i$ - величина заряда в точке $x_i$\n",
    "* $h_i$ - радиус действия потенциала с центром в точке $h$\n",
    "* $K(r) = \\frac{1}{r}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5c8f60",
   "metadata": {},
   "source": [
    "### Задача 5(3 балла)\n",
    "\n",
    "1. Реализуйте метод потенциальных функций для датасета, сгенерированого ниже. \n",
    "2. Веса может взять равными 1.\n",
    "3. $h = 1$. \n",
    "4. $K(r) = \\frac{1}{r}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff49285",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mДля выполнения ячеек с \"base\" требуется пакет ipykernel.\n",
      "\u001b[1;31mВыполните следующую команду, чтобы установить \"ipykernel\" в среде Python. \n",
      "\u001b[1;31mКоманда: \"conda install -n base ipykernel --update-deps --force-reinstall\""
     ]
    }
   ],
   "source": [
    "# Создание синтетического датасета\n",
    "X, y = make_circles(n_samples=200, factor=0.9, noise=0.01, random_state=42)\n",
    "\n",
    "# Визуализация датасета\n",
    "plt.scatter(X[y==0, 0], X[y==0, 1], c='green', label='Класс 0')\n",
    "plt.scatter(X[y==1, 0], X[y==1, 1], c='skyblue', label='Класс 1')\n",
    "plt.xlabel('Признак 1')\n",
    "plt.ylabel('Признак 2')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22507036",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mДля выполнения ячеек с \"base\" требуется пакет ipykernel.\n",
      "\u001b[1;31mВыполните следующую команду, чтобы установить \"ipykernel\" в среде Python. \n",
      "\u001b[1;31mКоманда: \"conda install -n base ipykernel --update-deps --force-reinstall\""
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Классификатор метода потенциальных функций\n",
    "class PotentialFunctionKNN:\n",
    "    def __init__(self, k, potential_function):\n",
    "        self.k = k\n",
    "        self.potential_function = potential_function\n",
    "        self.X_train = None\n",
    "        self.y_train = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "        # Веса равные 1\n",
    "        self.weights = np.ones(len(y))\n",
    "\n",
    "    def predict(self, X):\n",
    "        y_pred = [self._predict(x) for x in X]\n",
    "        return np.array(y_pred)\n",
    "\n",
    "    def _predict(self, x):\n",
    "        # Вычисляем потенциал для точки x относительно всех тренировочных точек\n",
    "        potential = np.array([self.potential_function(x, x_train) for x_train in self.X_train])\n",
    "        \n",
    "        # Умножаем потенциалы на веса соответствующих точек\n",
    "        weights_by_class = np.zeros(len(np.unique(self.y_train)))\n",
    "        for i, w in enumerate(potential):\n",
    "            weights_by_class[self.y_train[i]] += w * self.weights[i]\n",
    "        \n",
    "        return np.argmax(weights_by_class)\n",
    "\n",
    "# Функция потенциала\n",
    "def potential_function(x, x_train, h=1):\n",
    "    r = np.sqrt(np.sum((x - x_train) ** 2))\n",
    "    return 1 / (r / h) if r != 0 else float('inf')\n",
    "\n",
    "# Разделение на обучающий и тестовый наборы\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=22)\n",
    "\n",
    "# Создание экземпляра классификатора и применение к данным\n",
    "k = 5  # Вы можете экспериментировать с различным числом k\n",
    "clf = PotentialFunctionKNN(k=k, potential_function=potential_function)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Оценка точности\n",
    "accuracy = np.mean(y_pred == y_test)\n",
    "print(f'Точность классификатора метода потенциальных функций: {accuracy:.2f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb11dddc",
   "metadata": {},
   "source": [
    "## 3. Итоги"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93edb4f",
   "metadata": {},
   "source": [
    "Классификация k-ближайших соседей (k-NN) - это простой метод машинного обучения. Вот несколько его плюсов и минусов:\n",
    "\n",
    "***Плюсы***:\n",
    "1. Простота и интуитивная понятность: k-NN легко понять и реализовать. Он не имеет сложных гиперпараметров, обучение модели сводится к хранению обучающего набора данных.\n",
    "2. Нет обучения: k-NN - ленивый алгоритм, что означает, что нет фазы обучения. Это позволяет быстро адаптироваться к новым данным.\n",
    "3. Хорошо работает для простых задач: на небольших наборах данных с небольшим количеством признаков k-NN может дать неплохие результаты.\n",
    "\n",
    "***Минусы***:\n",
    "1. Высокие вычислительные затраты на предсказание: при больших объемах данных k-NN может быть медленным, так как для предсказания класса необходимо вычислить расстояние до всех обучающих примеров.\n",
    "2. Чувствительность к выбору параметра k: выбор значения k (количества соседей) может сильно влиять на результаты классификации.\n",
    "3. Неэффективен для данных с большим количеством признаков: при большом количестве признаков, особенно если они не нормализованы, алгоритм может работать менее эффективно из-за \"проклятия размерности\".\n",
    "4. Нет понимания глубины признаков: k-NN не учитывает важность признаков и не выявляет глубинные закономерности в данных.\n",
    "\n",
    "Несмотря на свои недостатки, k-NN может быть полезным методом в некоторых случаях, особенно при работе с небольшими объемами данных и простыми задачами."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49106e54",
   "metadata": {},
   "source": [
    "### Задача 6(1 балл)\n",
    "\n",
    "Приведите пример, когда метод k-NN может давать плохие результаты. Почему?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d62c8ca",
   "metadata": {},
   "source": [
    "Метод k-NN может давать плохие результаты в следующих ситуациях:\n",
    "\n",
    "1. Высокая размерность данных («проклятие размерности»): В пространствах с высокой размерностью точки могут оказаться равноудаленными друг от друга, что затрудняет идентификацию близких соседей. \n",
    "2. Неравномерное распределение классов: Если один класс имеет значительно больше примеров, чем другой, k-NN может быть смещён в сторону преобладающего класса.\n",
    "3. Шумные данные и выбросы: k-NN очень чувствителен к шумным данным и выбросам, поскольку они могут сильно повлиять на расчет расстояния между точками.\n",
    "4. Некорректно выбранное значение k: Слишком маленькое значение k может привести к переобучению, а слишком большое - к тому, что классификация будет основана на слишком обширном округе рассматриваемых точек.\n",
    "5. Зависимые признаки: Если признаки высоко скоррелированы, может быть трудно выявить настоящие закономерности в данных.\n",
    "6. Неправильно масштабированные признаки: Поскольку k-NN использует метрики расстояния для нахождения ближайших соседей, разный масштаб признаков может привести к доминированию некоторых признаков над другими. \n",
    "\n",
    "Во всех этих случаях подход k-NN может испытывать трудности с классификацией и, как результат, давать плохие результаты."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
